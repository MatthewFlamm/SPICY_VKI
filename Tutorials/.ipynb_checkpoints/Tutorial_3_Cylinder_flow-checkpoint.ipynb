{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070d2146",
   "metadata": {},
   "source": [
    "# SPICY Tutorial 3\n",
    "\n",
    "In this tutorial, we implement a constrained regression of a 2D velocity field, and we combine the lessons learned in the previous two tutorials to compute pressure fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134e5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "from spicy_class_m import spicy\n",
    "\n",
    "# This is for plot customization\n",
    "fontsize = 12\n",
    "plt.rc('text', usetex=True)      \n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['font.size'] = fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8781fc6",
   "metadata": {},
   "source": [
    "This test case is the 2D flow past a cylinder which is a typical benchmark test case. The data is taken from https://github.com/Raocp/PINN-laminar-flow. The geometry has a height of $0.41\\,$m, a length of $1.1\\,$m and the cylinder a radius of $0.02\\,$m. The solution is provided in the form of a Matlab file which is read with scipy.\n",
    "\n",
    "For the preparation of the dataset, we must first remove the points at the inlet and at the wall, as these are given in the form of constraints. Afterwards, we can extract a defined number of points for our regression (up to 18755). As for the Oseen vortex, we add 10% noise to the velocity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7f0673",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'FluentSol.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FluentSol.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20736/3909265698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Load the matlab data from the ansys solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FluentSol.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# Extract the x, y values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \"\"\"\n\u001b[0;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FluentSol.mat'"
     ]
    }
   ],
   "source": [
    "# Fix random seed to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Properties of the domain and flow\n",
    "R = 0.05 # m\n",
    "H = 0.41 # m\n",
    "L = 1.1 # m\n",
    "mu = 2e-2 # Pa s\n",
    "rho = 1 # kg/m^3\n",
    "\n",
    "# Load the matlab data from the ansys solution\n",
    "data = scipy.io.loadmat('FluentSol.mat')\n",
    "# Extract the x, y values\n",
    "X = data['x'].reshape(-1)\n",
    "Y = data['y'].reshape(-1) \n",
    "# Extract the velocities\n",
    "U = data['vx'].reshape(-1)\n",
    "V = data['vy'].reshape(-1)\n",
    "P = data['p'].reshape(-1)\n",
    "\n",
    "# Here, we remove the points at the inlet and at the wall, as they are given by the constraints\n",
    "inlet_and_wall_remover = np.invert(np.logical_or(np.logical_and(U==0, V==0), X==0))\n",
    "# Remove the points\n",
    "X = X[inlet_and_wall_remover]\n",
    "Y = Y[inlet_and_wall_remover]\n",
    "P = P[inlet_and_wall_remover]\n",
    "U = U[inlet_and_wall_remover]\n",
    "V = V[inlet_and_wall_remover]\n",
    "\n",
    "# From the remaining points we can choose to sample a random amount if we want to go for a smaller test case. In this\n",
    "# tutorial, we take the maximum number of points which is 18755\n",
    "n_p = 18755\n",
    "random_points_indices = np.random.randint(low=0, high=len(X), size=n_p)\n",
    "# Select the data points\n",
    "X = X[random_points_indices]\n",
    "Y = Y[random_points_indices]\n",
    "P = P[random_points_indices]\n",
    "U = U[random_points_indices]\n",
    "V = V[random_points_indices]\n",
    "\n",
    "# Add 10% noise to the velocity field\n",
    "q = 0.1\n",
    "U_noise = U * (1 + q * np.random.uniform(-1, 1, size = U.shape))\n",
    "V_noise = V * (1 + q * np.random.uniform(-1, 1, size = V.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1a44c",
   "metadata": {},
   "source": [
    "## Velocity regression\n",
    "\n",
    "We start with the regression of the velocity field.\n",
    "\n",
    "#### Step 1: Initialize the SPICY class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vel = spicy([U_noise,V_noise], [X,Y], basis='gauss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58f1b2",
   "metadata": {},
   "source": [
    "#### Step 2: Peform the clustering\n",
    "\n",
    "The cylinder has some global 'trends': Behind the cylinder, both the pressure and the velocity field do not experience sharp gradients. Therefore, it is useful to have some flat RBFs, which is why we add the third clustering level which gives very flat RBFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ac2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vel.clustering([6,50,1800], r_mM=[0.015,0.5], eps_l=0.83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759989b",
   "metadata": {},
   "source": [
    "#### Step 3: Define the boundary conditions\n",
    "\n",
    "For the velocity field, we have Dirichlet and divergence-free conditions. On each of the five boundaries, we sample 150 constraint points, removing duplicates. The Dirichlet conditions are a velocity of $0$ at the top, bottom and cylinder wall as well as a parabolic profile at the inlet. In these points, we also enforce a divergence-free flow. At the outlet, a divergence-free flow is also enforced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d37643",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of constraints on each boundary\n",
    "n_c = 150 \n",
    "\n",
    "# Left boundary\n",
    "X_Div1 = np.zeros(n_c)\n",
    "Y_Div1 = np.linspace(0, H, n_c)\n",
    "U_Dir1 = 4*(H-Y_Div1)*Y_Div1/H**2\n",
    "V_Dir1 = np.zeros(X_Div1.shape)\n",
    "# Bottom boundary\n",
    "X_Div2 = np.linspace(0, L, n_c)\n",
    "Y_Div2 = np.zeros(n_c)\n",
    "U_Dir2 = np.zeros(X_Div2.shape)\n",
    "V_Dir2 = np.zeros(X_Div2.shape)\n",
    "# Right boundary\n",
    "X_Div3 = np.ones(n_c-2)*L\n",
    "Y_Div3 = np.linspace(0, H, n_c)[1:-1]\n",
    "# Top boundary\n",
    "X_Div4 = np.linspace(0, L, n_c)\n",
    "Y_Div4 = np.ones(n_c)*H\n",
    "U_Dir4 = np.zeros(X_Div4.shape)\n",
    "V_Dir4 = np.zeros(X_Div4.shape)\n",
    "# Cylinder boundary\n",
    "alphaT = np.linspace(0, 2*np.pi, n_c, endpoint = False)\n",
    "X_Div5 = 0.2+R*np.cos(alphaT)\n",
    "Y_Div5 = 0.2+R*np.sin(alphaT)\n",
    "U_Dir5 = np.zeros(X_Div5.shape)\n",
    "V_Dir5 = np.zeros(X_Div5.shape)\n",
    "\n",
    "# We assemble the velocity constraints for Dirichlet\n",
    "X_Dir = np.concatenate((X_Div1, X_Div2, X_Div4, X_Div5))\n",
    "Y_Dir = np.concatenate((Y_Div1, Y_Div2, Y_Div4, Y_Div5))\n",
    "U_Dir = np.concatenate((U_Dir1, U_Dir2, U_Dir4, U_Dir5))\n",
    "V_Dir = np.concatenate((V_Dir1, V_Dir2, V_Dir4, V_Dir5))\n",
    "# and Divergence-free flow\n",
    "X_Div = np.concatenate((X_Div1, X_Div2, X_Div3, X_Div4, X_Div5))\n",
    "Y_Div = np.concatenate((Y_Div1, Y_Div2, Y_Div3, Y_Div4, Y_Div5))\n",
    "\n",
    "# We remove the duplicates in the Dirchlet \n",
    "_, valid_idcs = np.unique(np.column_stack((X_Div, Y_Div)), return_index = True, axis = 0)\n",
    "X_Div = X_Div[valid_idcs]\n",
    "Y_Div = Y_Div[valid_idcs]\n",
    "DIV = [X_Div, Y_Div]\n",
    "# and Divergence-free conditions\n",
    "_, valid_idcs = np.unique(np.column_stack((X_Dir, Y_Dir)), return_index = True, axis = 0)\n",
    "X_Dir = X_Dir[valid_idcs]\n",
    "Y_Dir = Y_Dir[valid_idcs]\n",
    "U_Dir = U_Dir[valid_idcs]\n",
    "V_Dir = V_Dir[valid_idcs]\n",
    "DIR = [X_Dir, Y_Dir, U_Dir, V_Dir]\n",
    "\n",
    "# We set the constraints in these points and also place additional RBFs in each of these points\n",
    "SP_vel.vector_constraints(DIR=DIR, DIV=DIV, extra_RBF=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa7490",
   "metadata": {},
   "source": [
    "We can look at the clustering result, the left-hand side shows the RBFs in 2D, the right hand side shows the diameter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f013535",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vel.plot_RBFs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03b6a2",
   "metadata": {},
   "source": [
    "#### Step 4: Assemble the linear system\n",
    "We assemble the regression, with a penalty for a divergence-free flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vel.Assembly_Regression(alpha_div=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106b3b",
   "metadata": {},
   "source": [
    "#### Step 5: Solve the linear system\n",
    "We solve the system, with a fixed condition number of $10^8$ for the matrix $A$. The matrix $M$ is only regularized in this way if the cholesky factorization fails. This is the case here, so we make use of the regularization for $M$ as well with the same conditioning number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vel.Solve(K_cond=1e12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfc398",
   "metadata": {},
   "source": [
    "#### Step 6: Obtain the solution\n",
    "Here, we use the same grid points as before for an easier comparison, However, this grid can be completely arbitrary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_velocity = SP_vel.Get_Sol(grid=[X,Y])\n",
    "# Extract individual velocity components\n",
    "U_calc = solution_velocity[:n_p]\n",
    "V_calc = solution_velocity[n_p:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa85e8e",
   "metadata": {},
   "source": [
    "We can now compute the error in the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitude of the RBF solution\n",
    "U_magn_calc = np.sqrt(U_calc**2 + V_calc**2)\n",
    "# Compute the magnitude of the analytical solution\n",
    "U_magn = np.sqrt(U**2 + V**2)\n",
    "# Compute the error in the magnitude\n",
    "error_magn = np.linalg.norm(U_magn_calc - U_magn) / np.linalg.norm(U_magn)\n",
    "# Error in u\n",
    "error_u = np.linalg.norm(U_calc - U) / np.linalg.norm(U)\n",
    "# Error in v\n",
    "error_v = np.linalg.norm(V_calc - V) / np.linalg.norm(V)\n",
    "\n",
    "print('Total velocity error: {0:.3f}%'.format(error_magn*100))\n",
    "print('Velocity error in u:  {0:.3f}%'.format(error_u*100))\n",
    "print('Velocity error in v:  {0:.3f}%'.format(error_v*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb077a73",
   "metadata": {},
   "source": [
    "We achieve a very good error below 2% on the global velocity magnitude. This is mostly dominated by the flow in $x$-direction as this is the main flow component with the highest magnitude. This is also evidenced by the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f1bf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(15,6), dpi=100, sharex=True, sharey=True)\n",
    "axes[0,0].scatter(X, Y, c=U_calc, s=10)\n",
    "axes[1,0].scatter(X, Y, c=U, s=10)\n",
    "axes[2,0].scatter(X, Y, c=np.abs(U_calc-U), s=10) \n",
    "\n",
    "axes[0,1].scatter(X, Y, c=V_calc, s=10)\n",
    "axes[1,1].scatter(X, Y, c=V, s=10)\n",
    "axes[2,1].scatter(X, Y, c=np.abs(V_calc-V), s=10)  \n",
    "\n",
    "axes[0,2].scatter(X, Y, c=U_magn_calc, s=10)\n",
    "axes[1,2].scatter(X, Y, c=U_magn, s=10)\n",
    "axes[2,2].scatter(X, Y, c=np.abs(U_magn_calc-U_magn), s=10) \n",
    "\n",
    "\n",
    "axes[0,0].set_ylabel('RBF Regression') \n",
    "axes[1,0].set_ylabel('Ground truth')  \n",
    "axes[2,0].set_ylabel('Absolute difference')  \n",
    "\n",
    "axes[0,0].set_title('$u$') \n",
    "axes[0,1].set_title('$v$')  \n",
    "axes[0,2].set_title('$||\\mathbf{u}||_2^2$')      \n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect(1)      \n",
    "fig.tight_layout()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea23a78",
   "metadata": {},
   "source": [
    "From left to right, the figure shows the velocity component $u$, $v$ as well as the magnitude. From top to bottom the rows show the computed velocity, the ground truth and the absolute difference. The error is uniformly distributed and strongest around the cylinder where the largest gradients are present which is expected. With the analytic expression of the velocity field, we can now continue with the pressure integration\n",
    "\n",
    "\n",
    "\n",
    "## Pressure integration\n",
    "\n",
    "For the pressure, we must compute two quantities from the velocity field. The first is the r.h.s. of equation (21) which is available analytically. The second are the values of the Neumann conditions on the boundaries, from equation (29)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ae1b1",
   "metadata": {},
   "source": [
    "We evaluate the source term on the original grid points, but this can also be an arbitrary grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the source term\n",
    "source_term = SP_vel.Evaluate_Source_Term(grid=[X,Y], rho=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd7a81",
   "metadata": {},
   "source": [
    "For the boundary conditions, we must again define the points in which we want to compute them. In the simulations, there is a constant pressure of $0$ at the outlet, which we enforce with 148 Dirichlet boundary conditions at the outlet. On the other boundaries, we compute the normal derivative of the pressure based on the velocity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90058b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of constraints on each boundary\n",
    "n_c = 150 \n",
    "\n",
    "# We start with the Neumann conditions\n",
    "# Left boundary\n",
    "X_Pres_N1 = np.zeros(n_c)\n",
    "Y_Pres_N1 = np.linspace(0, H, n_c)\n",
    "# Bottom boundary\n",
    "X_Pres_N2 = np.linspace(0.0,L,n_c)\n",
    "Y_Pres_N2 = np.zeros(n_c)\n",
    "# Top boundary\n",
    "X_Pres_N4 = np.linspace(0, L, n_c)\n",
    "Y_Pres_N4 = np.ones(n_c)*H\n",
    "# Cylinder boundary\n",
    "alpha_P = np.linspace(0, 2*np.pi, n_c, endpoint = False) \n",
    "X_Pres_N5 = 0.2 + R*np.cos(alpha_P)\n",
    "Y_Pres_N5 = 0.2 + R*np.sin(alpha_P)\n",
    "# Assemble the the entire array of Neumann points\n",
    "X_Pres_N=np.hstack((X_Pres_N1, X_Pres_N2, X_Pres_N4, X_Pres_N5))\n",
    "Y_Pres_N=np.hstack((Y_Pres_N1, Y_Pres_N2, Y_Pres_N4, Y_Pres_N5))\n",
    "\n",
    "# We assemble the normals in the same way\n",
    "# Left boundary\n",
    "n_x_1 = np.ones(X_Pres_N1.shape)*(-1)\n",
    "n_y_1 = np.ones(X_Pres_N1.shape)*0\n",
    "# Bottom boundary\n",
    "n_x_2 = np.ones(X_Pres_N2.shape)*0\n",
    "n_y_2 = np.ones(X_Pres_N2.shape)*(-1)\n",
    "# Top boundary\n",
    "n_x_4 = np.ones(X_Pres_N4.shape)*0\n",
    "n_y_4 = np.ones(X_Pres_N4.shape)*1\n",
    "# Cylinder boundary\n",
    "n_x_5 = np.ones(X_Pres_N5.shape)*(-np.cos(alpha_P))\n",
    "n_y_5 = np.ones(X_Pres_N5.shape)*(-np.sin(alpha_P))\n",
    "# Assemble to obtain the entire array of Neumann normals\n",
    "n_x = np.hstack((n_x_1, n_x_2, n_x_4, n_x_5))\n",
    "n_y = np.hstack((n_y_1, n_y_2, n_y_4, n_y_5))  \n",
    "\n",
    "# Remove the duplicates for the normals\n",
    "_, valid_idcs = np.unique(np.column_stack((X_Pres_N, Y_Pres_N)),\n",
    "                          return_index = True, axis = 0)\n",
    "X_Pres_N = X_Pres_N[valid_idcs]\n",
    "Y_Pres_N = Y_Pres_N[valid_idcs]\n",
    "n_x = n_x[valid_idcs]\n",
    "n_y = n_y[valid_idcs]\n",
    "\n",
    "# The last thing are the Dirichlet conditions at the outlet\n",
    "# Right boundary\n",
    "X_Pres_D3 = np.ones(n_c-2)*L\n",
    "Y_Pres_D3 = np.linspace(0, H, n_c)[1:-1]\n",
    "\n",
    "# Evaluate the Neumann conditions in these points\n",
    "P_Neu = SP_vel.Get_Pressure_Neumann(grid = [X_Pres_N, Y_Pres_N], normals = [n_x, n_y],\n",
    "                                    rho = rho, mu = mu)\n",
    "\n",
    "# The Dirichlet conditions do not have any overlap with the Neumann conditions, so we can just take them as they are\n",
    "X_Pres_D = X_Pres_D3\n",
    "Y_Pres_D = Y_Pres_D3\n",
    "P_Pres_D = np.zeros(X_Pres_D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c90680",
   "metadata": {},
   "source": [
    "Now, we have all of the quantities, that we need from the velocity. The velocity spicy class can now be deleted, to save memory but for the sake of this tutorial, all variables are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e09083",
   "metadata": {},
   "source": [
    "#### Step 1: Initialize the SPICY class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_pres = spicy([source_term], [X,Y], basis='gauss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec76d5",
   "metadata": {},
   "source": [
    "#### Step 2: Peform the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_pres.clustering([6,50,1800], r_mM=[0.015, 0.5], eps_l=0.83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540628cf",
   "metadata": {},
   "source": [
    "#### Step 3: Define the boundary conditions\n",
    "We use 195 Neumann and one Dirichlet boundary condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f80bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assemble our Neumann and Dirichlet B.C.\n",
    "NEU_P = [X_Pres_N, Y_Pres_N, n_x, n_y, P_Neu]\n",
    "DIR_P = [X_Pres_D, Y_Pres_D, P_Pres_D]\n",
    "\n",
    "# And, we set them\n",
    "SP_pres.scalar_constraints(DIR=DIR_P, NEU=NEU_P, extra_RBF=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3d3c2",
   "metadata": {},
   "source": [
    "#### Step 4: Assemble the linear system\n",
    "We assemble the regression, with no harmonic basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_pres.Assembly_Poisson(n_hb = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d396462",
   "metadata": {},
   "source": [
    "#### Step 5: Solve the linear system\n",
    "We solve the system, witha fixed condition number of $10^{12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e993ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_pres.Solve(K_cond=1e12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd545d78",
   "metadata": {},
   "source": [
    "#### Step 6 Obtain the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e4c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_calc = SP_pres.Get_Sol(grid=[X,Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0f065",
   "metadata": {},
   "source": [
    "We can now compute the error in the magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the pressure error\n",
    "error_p = np.linalg.norm(P_calc-P)/np.linalg.norm(P)\n",
    "print('Total pressure error: {0:.3f}%'.format(error_p*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9e1f2",
   "metadata": {},
   "source": [
    "We close by comparing the calculated and ground truth pressure field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,3), dpi=100, ncols=3, sharey=True)\n",
    "axes[0].scatter(X, Y, c=P_calc, s=10)\n",
    "axes[0].set_title('Computed pressure field')\n",
    "axes[1].scatter(X, Y, c=P, s=10)\n",
    "axes[1].set_title('Analytical pressure field')\n",
    "axes[2].scatter(X, Y, c=np.abs(P_calc-P), s=10)\n",
    "axes[2].set_title('Absolute difference')           \n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect(1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a76247",
   "metadata": {},
   "source": [
    "As expected, the difference in the pressure field is the strongest in the center, where the largest gradient is located. However, the error is neglibile given the fact that there is 10% noise on the velocity data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
